# src/services/ai_service.py
import asyncio
import json
import os
import re
import subprocess
import tempfile
import unicodedata
import uuid  # æ–°å¢å¯¼å…¥
from pathlib import Path
import sys
import requests
import whisper
from openai import OpenAI
from openai.types.chat import ChatCompletionSystemMessageParam, ChatCompletionUserMessageParam
from rich.progress import Progress, BarColumn, TextColumn, DownloadColumn, TransferSpeedColumn

import src.config as config
from src import prompts
from src.utils import logger
import warnings


class LocalTTSEngine:
    """
    ä½¿ç”¨Piper TTSçš„æœ¬åœ°æ–‡æœ¬è½¬è¯­éŸ³å¼•æ“ã€‚
    è´Ÿè´£æ¨¡å‹ç®¡ç†å’Œè¯­éŸ³åˆæˆã€‚
    """
    def __init__(self, model: str = "en_US-libritts_r-medium"):
        self.model_name = model
        # å°†æ¨¡å‹æ–‡ä»¶å­˜æ”¾åœ¨é¡¹ç›®æ ¹ç›®å½•çš„.modelsæ–‡ä»¶å¤¹ä¸­ï¼Œæ–¹ä¾¿ç®¡ç†
        self.models_dir = Path(".models")
        self.models_dir.mkdir(exist_ok=True)

        python_dir = Path(sys.prefix)
        self.piper_exe_path = python_dir / "Scripts" / "piper.exe"

        self.model_path = self.models_dir / f"{self.model_name}.onnx"
        self.model_config_path = self.models_dir / f"{self.model_name}.onnx.json"

    async def ensure_model_exists(self):
        """æ£€æŸ¥å¹¶è‡ªåŠ¨ä¸‹è½½æ‰€éœ€çš„TTSæ¨¡å‹ã€‚"""
        if not self.model_path.exists() or not self.model_config_path.exists():
            logger.info(f"ğŸ“¥ é¦–æ¬¡ä½¿ç”¨ï¼Œéœ€è¦ä¸‹è½½Piper TTSæ¨¡å‹: {self.model_name}")
            await self._download_model()

    async def _download_model(self):
        """
        ä½¿ç”¨requestsåº“å’Œrichè¿›åº¦æ¡ï¼Œä»¥æ›´å®‰å…¨çš„æ–¹å¼ä¸‹è½½Piperè¯­éŸ³æ¨¡å‹ã€‚
        - æ£€æŸ¥HTTPçŠ¶æ€ç ã€‚
        - ä¸‹è½½åˆ°.partä¸´æ—¶æ–‡ä»¶ï¼ŒæˆåŠŸåå†é‡å‘½åã€‚
        - æ¸…ç†å¤±è´¥çš„ä¸‹è½½ã€‚
        """
        try:
            parts = self.model_name.split('-')
            if len(parts) != 3:
                raise ValueError(f"æ¨¡å‹åç§° '{self.model_name}' æ ¼å¼ä¸æ­£ç¡®ï¼Œåº”ä¸º 'locale-voice-quality'ã€‚")
            
            locale, voice, quality = parts
            lang = locale.split('_')[0]

            base_url = f"https://hf-mirror.com/rhasspy/piper-voices/resolve/main/{lang}/{locale}/{voice}/{quality}/{self.model_name}"
            
            logger.info(f"æ ¹æ®æ¨¡å‹åç§°åŠ¨æ€æ„å»ºä¸‹è½½URL: {base_url}")

            # å®šä¹‰è¦ä¸‹è½½çš„æ–‡ä»¶å’Œå®ƒä»¬çš„ç›®æ ‡è·¯å¾„
            files_to_download = {
                f"{self.model_name}.onnx": self.model_path,
                f"{self.model_name}.onnx.json": self.model_config_path
            }

            # ä½¿ç”¨ rich.progress åˆ›å»ºä¸€ä¸ªç¾è§‚çš„è¿›åº¦æ¡
            progress = Progress(
                TextColumn("[bold blue]{task.fields[filename]}", justify="right"),
                BarColumn(bar_width=None),
                "[progress.percentage]{task.percentage:>3.1f}%",
                "â€¢",
                DownloadColumn(),
                "â€¢",
                TransferSpeedColumn(),
            )

            def download_job(url, dest_path):
                dest_path_part = dest_path.with_suffix(dest_path.suffix + '.part')
                task_id = progress.add_task("download", filename=dest_path.name, start=False)
                
                try:
                    response = requests.get(url, stream=True, timeout=30)
                    response.raise_for_status()
                    
                    total_size = int(response.headers.get('content-length', 0))
                    progress.start_task(task_id)
                    progress.update(task_id, total=total_size)
                    
                    with open(dest_path_part, 'wb') as f:
                        for chunk in response.iter_content(chunk_size=8192):
                            f.write(chunk)
                            progress.update(task_id, advance=len(chunk))

                    # ä¸‹è½½æˆåŠŸåé‡å‘½å
                    dest_path_part.rename(dest_path)
                    logger.debug(f"æ–‡ä»¶ '{dest_path.name}' ä¸‹è½½æˆåŠŸã€‚")

                except requests.RequestException as e:
                    # å¦‚æœå‘ç”Ÿç½‘ç»œé”™è¯¯ï¼Œæ¸…ç†.partæ–‡ä»¶
                    if dest_path_part.exists():
                        dest_path_part.unlink()
                    # å°†å¼‚å¸¸å‘ä¸ŠæŠ›å‡ºï¼Œä»¥ä¾¿å¤–å±‚å¯ä»¥æ•è·
                    raise e
                finally:
                    progress.stop_task(task_id)
                    progress.update(task_id, visible=False)


            with progress:
                for filename, path in files_to_download.items():
                    url = f"{base_url}{'.onnx' if filename.endswith('.onnx') else '.onnx.json'}"
                    # ä½¿ç”¨ to_thread åœ¨å¼‚æ­¥å‡½æ•°ä¸­è¿è¡ŒåŒæ­¥çš„ä¸‹è½½ä»£ç 
                    await asyncio.to_thread(download_job, url, path)

            # æœ€ç»ˆæ ¡éªŒæ–‡ä»¶æ˜¯å¦å­˜åœ¨
            if self.model_path.exists() and self.model_config_path.exists():
                logger.success("âœ… æ¨¡å‹åŠé…ç½®æ–‡ä»¶ä¸‹è½½å®Œæˆã€‚")
            else:
                raise FileNotFoundError("æ¨¡å‹æ–‡ä»¶ä¸‹è½½åæ ¡éªŒå¤±è´¥ï¼Œä¸€ä¸ªæˆ–å¤šä¸ªæ–‡ä»¶ä¸å­˜åœ¨ã€‚")

        except Exception as e:
            logger.error(f"æ¨¡å‹ä¸‹è½½å¤±è´¥: {e}")
            # å†æ¬¡ç¡®ä¿æ¸…ç†
            for _, path in files_to_download.items():
                part_file = path.with_suffix(path.suffix + '.part')
                if part_file.exists():
                    part_file.unlink()
            raise


    @staticmethod
    def _clean_text_for_tts(text: str) -> str:
        """
        å¯¹æ–‡æœ¬è¿›è¡Œå‡€åŒ–ï¼Œä¸ºçº¯è‹±æ–‡TTSå¼•æ“å‡†å¤‡å…¼å®¹æ€§è‰¯å¥½çš„è¾“å…¥ã€‚
        """
        if not isinstance(text, str):
            return ""

        # 1. ä½¿ç”¨ NFKC è§„èŒƒåŒ–å¤„ç†å…¼å®¹æ€§å­—ç¬¦ï¼ˆä¾‹å¦‚å…¨è§’åˆ°åŠè§’ï¼‰
        normalized_text = unicodedata.normalize('NFKC', text)

        # 2. å®šä¹‰ä¸€ä¸ªæ›´å…¨é¢çš„ç‰¹æ®Šæ ‡ç‚¹ç¬¦å·æ›¿æ¢è¡¨
        replacements = {
            'â€”': '-',  # EM DASH
            'â€“': '-',  # EN DASH
            'â€¦': '...',  # HORIZONTAL ELLIPSIS
            'ã€Œ': '"',  # LEFT CORNER BRACKET
            'ã€': '"',  # RIGHT CORNER BRACKET
            'ã€': '"',  # LEFT WHITE CORNER BRACKET
            'ã€': '"',  # RIGHT WHITE CORNER BRACKET
            'ã€Š': '"',  # LEFT DOUBLE ANGLE BRACKET
            'ã€‹': '"',  # RIGHT DOUBLE ANGLE BRACKET
            'ã€ˆ': "'",  # LEFT ANGLE BRACKET
            'ã€‰': "'",  # RIGHT ANGLE BRACKET
            'â€œ': '"',
            'â€': '"',
            'â€˜': "'",
            'â€™': "'",
            '`': "'",  # åå¼•å·
            'Â´': "'",  # é”éŸ³ç¬¦
            'â€²': "'",  # åˆ†ç¬¦å·
            'â€³': '"',  # ç§’ç¬¦å·
        }
        for old, new in replacements.items():
            normalized_text = normalized_text.replace(old, new)

        # 3. ç™½åå•è¿‡æ»¤ï¼šåªä¿ç•™è‹±æ–‡ã€æ•°å­—å’ŒæŒ‡å®šçš„æ ‡ç‚¹ç¬¦å·
        # ä½¿ç”¨æ­£åˆ™è¡¨è¾¾å¼ç§»é™¤æ‰€æœ‰ä¸ç¬¦åˆç™½åå•çš„å­—ç¬¦
        allowed_chars_pattern = r"[^a-zA-Z0-9\s.,?!'\"():;-]"
        clean_text = re.sub(allowed_chars_pattern, '', normalized_text)
        
        # 4. å»é™¤å¤šä½™çš„ç©ºç™½å­—ç¬¦
        clean_text = re.sub(r'\s+', ' ', clean_text).strip()

        return clean_text

    async def synthesize(self, text: str, length_scale: float = 1.0, noise_scale: float = 0.667, noise_w: float = 0.8) -> bytes | None:
        """
        ä½¿ç”¨Piper TTSå°†æ–‡æœ¬åˆæˆä¸ºè¯­éŸ³ï¼Œå¹¶è¿”å›WAVæ–‡ä»¶çš„å­—èŠ‚æ•°æ®ã€‚
        æ–°å¢length_scale, noise_scale, noise_wå‚æ•°ä»¥æ§åˆ¶è¯­é€Ÿå’Œå‘éŸ³é£æ ¼ã€‚
        """
        # æ­¥éª¤ 1: å‡€åŒ–æ–‡æœ¬è¾“å…¥
        clean_text = self._clean_text_for_tts(text)
        if not clean_text:
            logger.warning(f"åŸå§‹æ–‡æœ¬ '{text[:30]}...' å‡€åŒ–åä¸ºç©ºï¼Œè·³è¿‡TTSåˆæˆã€‚")
            return None

        # åˆ›å»ºä¸€ä¸ªä¸´æ—¶çš„WAVæ–‡ä»¶è·¯å¾„
        output_path = Path(tempfile.gettempdir()) / f"piper_output_{uuid.uuid4().hex}.wav"
        
        try:
            await self.ensure_model_exists()

            # æ£€æŸ¥ piper.exe æ˜¯å¦å­˜åœ¨äºä¾¿æºç‰ˆPythonçš„Scriptsç›®å½•ä¸­
            if not self.piper_exe_path.exists():
                logger.error(f"TTSå¼•æ“ 'piper.exe' æœªåœ¨ä¾¿æºå¼ç¯å¢ƒçš„Scriptsæ–‡ä»¶å¤¹ä¸­æ‰¾åˆ°ã€‚")
                logger.error(f"é¢„æœŸè·¯å¾„: {self.piper_exe_path}")
                logger.error("è¯·ç¡®è®¤ 'piper-tts' æ˜¯å¦å·²é€šè¿‡ 'run.bat' è„šæœ¬æ­£ç¡®å®‰è£…ã€‚")
                return None

            logger.debug(f"æ­£åœ¨ä½¿ç”¨Piper TTSåˆæˆè¯­éŸ³ (è¯­é€Ÿ: {length_scale}, noise_scale: {noise_scale}, noise_w: {noise_w}): '{clean_text[:30]}...'")
            piper_command = [
                str(self.piper_exe_path),
                "--model", str(self.model_path),
                "--output_file", str(output_path),
                "--length_scale", str(length_scale),
                "--noise_scale", str(noise_scale),
                "--noise_w", str(noise_w)
            ]

            # åœ¨Windowsä¸Šï¼Œä½¿ç”¨CREATE_NO_WINDOWæ ‡å¿—æ¥éšè—å­è¿›ç¨‹çš„æ§åˆ¶å°çª—å£
            creation_flags = subprocess.CREATE_NO_WINDOW if os.name == 'nt' else 0
            
            process = await asyncio.create_subprocess_exec(
                *piper_command,
                stdin=subprocess.PIPE, stdout=subprocess.PIPE, stderr=subprocess.PIPE,
                creationflags=creation_flags
            )
            
            _, stderr = await process.communicate(clean_text.encode('utf-8'))
            
            if process.returncode == 0 and output_path.exists():
                with open(output_path, "rb") as f:
                    audio_bytes = f.read()
                
                logger.debug(f"Piper TTS è¯­éŸ³åˆæˆæˆåŠŸï¼Œè¿”å› {len(audio_bytes)} å­—èŠ‚æ•°æ®ã€‚")
                return audio_bytes
            else:
                raise Exception(f"Piperæ‰§è¡Œå¤±è´¥: {stderr.decode('utf-8', errors='ignore')}")

        except FileNotFoundError:
             # è¿™ä¸ªå¼‚å¸¸ç†è®ºä¸Šä¸åº”è¯¥å†è¢«è§¦å‘ï¼Œå› ä¸ºæˆ‘ä»¬å·²ç»æå‰æ£€æŸ¥äº†è·¯å¾„
             logger.error(f"å‘½ä»¤æ‰§è¡Œå¤±è´¥ï¼Œæ‰¾ä¸åˆ°æ–‡ä»¶: {self.piper_exe_path}")
             return None
        except Exception as e:
            logger.error(f"Piper TTS åˆæˆå¤±è´¥: {e}")
            return None
        finally:
            # ç¡®ä¿ä¸´æ—¶æ–‡ä»¶è¢«åˆ é™¤
            if output_path.exists():
                output_path.unlink()
			


class AIService:
    """
    AIæœåŠ¡ç±»ï¼Œå°è£…äº†æ‰€æœ‰ä¸AIæ¨¡å‹ï¼ˆWhisper, DeepSeek, æœ¬åœ°TTSï¼‰çš„äº¤äº’ã€‚
    """
    def __init__(self):
        """
        åˆå§‹åŒ–AIæœåŠ¡ï¼ŒåŠ è½½Whisperæ¨¡å‹ã€é…ç½®DeepSeekå®¢æˆ·ç«¯å’Œæœ¬åœ°TTSå¼•æ“ã€‚
        """
        logger.info("æ­£åœ¨åŠ è½½Whisperæ¨¡å‹...")
        
        # å¿½ç•¥ whisper åº“å…³äº FP16 åœ¨ CPU ä¸Šä¸å—æ”¯æŒçš„è­¦å‘Š
        warnings.filterwarnings("ignore", message="FP16 is not supported on CPU; using FP32 instead", category=UserWarning)
        self.whisper_model = whisper.load_model(config.WHISPER_MODEL)
        logger.info("Whisperæ¨¡å‹åŠ è½½å®Œæ¯•ã€‚")

        logger.info("æ­£åœ¨é…ç½®DeepSeekå®¢æˆ·ç«¯...")
        self.deepseek_client = OpenAI(api_key=config.DEEPSEEK_API_KEY, base_url=config.DEEPSEEK_BASE_URL)
        logger.info("DeepSeekå®¢æˆ·ç«¯é…ç½®å®Œæ¯•ã€‚")

        logger.info("æ­£åœ¨åˆå§‹åŒ–æœ¬åœ°TTSå¼•æ“...")
        self.local_tts_engine = LocalTTSEngine()
        logger.info("æœ¬åœ°TTSå¼•æ“åˆå§‹åŒ–å®Œæ¯•ã€‚")

    async def text_to_wav(self, text: str, length_scale: float = 1.0, noise_scale: float = 0.667, noise_w: float = 0.8) -> str | None:
        """
        ä½¿ç”¨æœ¬åœ°TTSå¼•æ“å°†æ–‡æœ¬è½¬æ¢ä¸ºWAVæ ¼å¼çš„éŸ³é¢‘æ–‡ä»¶ã€‚
        """
        # ç›´æ¥è°ƒç”¨æœ¬åœ°TTSå¼•æ“çš„synthesizeæ–¹æ³•ï¼Œå¹¶ä¼ é€’è¯­é€Ÿå’Œå‘éŸ³é£æ ¼å‚æ•°
        return await self.local_tts_engine.synthesize(text, length_scale, noise_scale, noise_w)
		
    def transcribe_media_from_url(self, url: str) -> str:
        """
        ä»URLä¸‹è½½åª’ä½“æ–‡ä»¶ï¼ˆéŸ³é¢‘æˆ–è§†é¢‘ï¼‰ï¼Œè½¬å½•ä¸ºæ–‡å­—ï¼Œç„¶ååˆ é™¤ä¸´æ—¶æ–‡ä»¶ã€‚
        """
        temp_file_path = None
        try:
            logger.info(f"æ­£åœ¨ä»URLä¸‹è½½åª’ä½“æ–‡ä»¶: {url}")
            response = requests.get(url, stream=True, headers=config.HEADERS, timeout=30)
            response.raise_for_status()

            # åˆ›å»ºä¸€ä¸ªè‡ªå®šä¹‰çš„ä¸´æ—¶æ–‡ä»¶å¤¹
            temp_dir = Path(".temp_downloads")
            temp_dir.mkdir(parents=True, exist_ok=True)  # å¦‚æœæ–‡ä»¶å¤¹ä¸å­˜åœ¨å°±åˆ›å»º

            # å»æ‰ URL ä¸­çš„æŸ¥è¯¢å‚æ•°éƒ¨åˆ†
            path_part = url.split('?')[0]  # å»æ‰æŸ¥è¯¢å‚æ•°
            path_part = path_part.split('#')[0]  # å»æ‰ URL ä¸­çš„ fragment éƒ¨åˆ†ï¼ˆ#åé¢çš„éƒ¨åˆ†ï¼‰

            # æå–æ–‡ä»¶åç¼€
            suffix = os.path.splitext(path_part)[1]

            if not suffix:
                # å¦‚æœæ²¡æœ‰åç¼€ï¼Œé€šè¿‡ MIME ç±»å‹æ¥æ¨æ–­
                content_type = response.headers.get('Content-Type')
                if 'video' in content_type:
                    suffix = '.mp4'
                elif 'audio' in content_type:
                    suffix = '.mp3'
                else:
                    suffix = '.tmp'  # é»˜è®¤åç¼€

            # ä¿å­˜æ–‡ä»¶åˆ°æŒ‡å®šç›®å½•å¹¶ç»™æ–‡ä»¶æ·»åŠ æ­£ç¡®çš„åç¼€
            with tempfile.NamedTemporaryFile(delete=False, suffix=suffix, dir=temp_dir) as temp_file:
                temp_file_path = temp_file.name
                for chunk in response.iter_content(chunk_size=8192):
                    temp_file.write(chunk)

            logger.info(f"åª’ä½“æ–‡ä»¶å·²ä¸´æ—¶ä¿å­˜è‡³: {temp_file_path}")
            return self.transcribe_media_file(temp_file_path)

        except requests.RequestException as e:
            logger.error(f"ä¸‹è½½åª’ä½“æ–‡ä»¶æ—¶å‘ç”Ÿé”™è¯¯: {e}")
            return ""
        except Exception as e:
            logger.error(f"å¤„ç†åª’ä½“æ–‡ä»¶URLæ—¶å‘ç”ŸæœªçŸ¥é”™è¯¯: {e}")
            return ""
        finally:
            if temp_file_path and os.path.exists(temp_file_path):
                os.remove(temp_file_path)
                logger.info(f"å·²æ¸…ç†ä¸´æ—¶æ–‡ä»¶: {temp_file_path}")

    def transcribe_media_file(self, file_path: str) -> str:
        """
        ä½¿ç”¨Whisperæ¨¡å‹å°†æŒ‡å®šçš„åª’ä½“æ–‡ä»¶ï¼ˆéŸ³é¢‘æˆ–è§†é¢‘ï¼‰è½¬æ¢ä¸ºæ–‡å­—ã€‚
        """
        logger.info(f"æ­£åœ¨è¿›è¡Œè¯­éŸ³è¯†åˆ«: {file_path}")
        try:
            result = self.whisper_model.transcribe(file_path)
            text = result.get("text", "")
            logger.info("è¯­éŸ³è¯†åˆ«å®Œæˆã€‚")
            return text
        except Exception as e:
            logger.error(f"è¯­éŸ³è¯†åˆ«è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {e}")
            return ""

    def get_chat_completion(self, prompt: str) -> dict | None:
        """
        è°ƒç”¨DeepSeekèŠå¤©æ¨¡å‹è·å–ç­”æ¡ˆï¼Œå¹¶è§£æè¿”å›çš„JSONã€‚
        """
        logger.info("æ­£åœ¨è¯·æ±‚DeepSeek AIè·å–ç­”æ¡ˆ (JSONæ¨¡å¼)...")
        try:
            messages = [
                ChatCompletionSystemMessageParam(role="system", content=prompts.SYSTEM_PROMPT),
                ChatCompletionUserMessageParam(role="user", content=prompt),
            ]
            
            ai_response = self.deepseek_client.chat.completions.create(
                model=config.DEEPSEEK_CHAT_MODEL,
                messages=messages,
                temperature=0.2,
                response_format={'type': 'json_object'}
            )
            
            answer_content = ai_response.choices[0].message.content
            logger.info("å·²æ”¶åˆ°DeepSeekçš„å›å¤ã€‚")

            try:
                json_data = json.loads(answer_content)
                logger.info("æˆåŠŸè§£æAIçš„ç­”æ¡ˆã€‚")
                return json_data
            except json.JSONDecodeError as e:
                logger.error(f"è§£æAIè¿”å›çš„JSONæ—¶å¤±è´¥: {e}")
                logger.error(f"å°è¯•è§£æçš„å­—ç¬¦ä¸²: {answer_content}")
                return None

        except Exception as e:
            logger.error(f"è°ƒç”¨DeepSeek APIæ—¶å‘ç”Ÿé”™è¯¯: {e}")
            return None
			

