# src/services/ai_service.py
import whisper
import re
import json
import requests
import tempfile
import os
import asyncio
import subprocess
from pathlib import Path
import uuid # æ–°å¢å¯¼å…¥
from openai import OpenAI
from openai.types.chat import ChatCompletionSystemMessageParam, ChatCompletionUserMessageParam
import src.config as config
from src import prompts

class LocalTTSEngine:
    """
    ä½¿ç”¨Piper TTSçš„æœ¬åœ°æ–‡æœ¬è½¬è¯­éŸ³å¼•æ“ã€‚
    è´Ÿè´£æ¨¡å‹ç®¡ç†å’Œè¯­éŸ³åˆæˆã€‚
    """
    def __init__(self, model: str = "en_US-libritts_r-medium"):
        self.model_name = model
        # å°†æ¨¡å‹æ–‡ä»¶å­˜æ”¾åœ¨é¡¹ç›®æ ¹ç›®å½•çš„.modelsæ–‡ä»¶å¤¹ä¸­ï¼Œæ–¹ä¾¿ç®¡ç†
        self.models_dir = Path(".models")
        self.models_dir.mkdir(exist_ok=True)
        self.model_path = self.models_dir / f"{self.model_name}.onnx"
        self.model_config_path = self.models_dir / f"{self.model_name}.onnx.json"

    async def ensure_model_exists(self):
        """æ£€æŸ¥å¹¶è‡ªåŠ¨ä¸‹è½½æ‰€éœ€çš„TTSæ¨¡å‹ã€‚"""
        if not self.model_path.exists() or not self.model_config_path.exists():
            print(f"ğŸ“¥ é¦–æ¬¡ä½¿ç”¨ï¼Œéœ€è¦ä¸‹è½½Piper TTSæ¨¡å‹: {self.model_name}")
            await self._download_model()

    async def _download_model(self):
        """ä»HuggingFaceåŠ¨æ€æ„å»ºURLå¹¶ä¸‹è½½Piperè¯­éŸ³æ¨¡å‹ã€‚"""
        try:
            # ä»æ¨¡å‹åç§°è§£æURLç»„ä»¶ï¼Œä¾‹å¦‚ "en_US-lessac-medium"
            parts = self.model_name.split('-')
            if len(parts) != 3:
                raise ValueError(f"æ¨¡å‹åç§° '{self.model_name}' æ ¼å¼ä¸æ­£ç¡®ï¼Œåº”ä¸º 'locale-voice-quality'ã€‚")
            
            locale, voice, quality = parts
            lang = locale.split('_')[0]

            base_url = f"https://huggingface.co/rhasspy/piper-voices/resolve/main/{lang}/{locale}/{voice}/{quality}/{self.model_name}"
            
            print(f"æ ¹æ®æ¨¡å‹åç§°åŠ¨æ€æ„å»ºä¸‹è½½URL: {base_url}")
            
            # ä¸‹è½½æ¨¡å‹æ–‡ä»¶
            print(f"æ­£åœ¨ä¸‹è½½æ¨¡å‹: {self.model_name}.onnx...")
            process = await asyncio.create_subprocess_shell(
                f'curl -L -o "{self.model_path}" "{base_url}.onnx"'
            )
            await process.wait()
            
            # ä¸‹è½½æ¨¡å‹é…ç½®æ–‡ä»¶
            print(f"æ­£åœ¨ä¸‹è½½æ¨¡å‹é…ç½®æ–‡ä»¶: {self.model_name}.onnx.json...")
            process = await asyncio.create_subprocess_shell(
                f'curl -L -o "{self.model_config_path}" "{base_url}.onnx.json"'
            )
            await process.wait()
            
            if self.model_path.exists() and self.model_path.stat().st_size > 1000 and \
               self.model_config_path.exists() and self.model_config_path.stat().st_size > 100:
                print("âœ… æ¨¡å‹ä¸‹è½½å’Œæ–‡ä»¶å¤§å°æ ¡éªŒå®Œæˆã€‚")
            else:
                raise FileNotFoundError("æ¨¡å‹æ–‡ä»¶ä¸‹è½½å¤±è´¥æˆ–æ–‡ä»¶å¤§å°å¼‚å¸¸ã€‚è¯·æ£€æŸ¥.modelsæ–‡ä»¶å¤¹ä¸‹çš„æ–‡ä»¶ã€‚")
                
        except Exception as e:
            print(f"âŒ æ¨¡å‹ä¸‹è½½å¤±è´¥: {e}")
            # å¦‚æœä¸‹è½½å¤±è´¥ï¼Œåˆ é™¤å¯èƒ½å·²åˆ›å»ºçš„æŸåæ–‡ä»¶
            if self.model_path.exists(): self.model_path.unlink()
            if self.model_config_path.exists(): self.model_config_path.unlink()
            raise

    async def synthesize(self, text: str, length_scale: float = 1.0, noise_scale: float = 0.667, noise_w: float = 0.8) -> bytes | None:
        """
        ä½¿ç”¨Piper TTSå°†æ–‡æœ¬åˆæˆä¸ºè¯­éŸ³ï¼Œå¹¶è¿”å›WAVæ–‡ä»¶çš„å­—èŠ‚æ•°æ®ã€‚
        æ–°å¢length_scale, noise_scale, noise_wå‚æ•°ä»¥æ§åˆ¶è¯­é€Ÿå’Œå‘éŸ³é£æ ¼ã€‚
        """
        # åˆ›å»ºä¸€ä¸ªä¸´æ—¶çš„WAVæ–‡ä»¶è·¯å¾„
        output_path = Path(tempfile.gettempdir()) / f"piper_output_{uuid.uuid4().hex}.wav"
        
        try:
            await self.ensure_model_exists()

            print(f"æ­£åœ¨ä½¿ç”¨Piper TTSåˆæˆè¯­éŸ³ (è¯­é€Ÿ: {length_scale}, noise_scale: {noise_scale}, noise_w: {noise_w}): '{text[:30]}...'")
            piper_command = [
                "piper", 
                "--model", str(self.model_path),
                "--output_file", str(output_path),
                "--length_scale", str(length_scale), # æ·»åŠ è¯­é€Ÿæ§åˆ¶å‚æ•°
                "--noise_scale", str(noise_scale),     # æ·»åŠ å™ªå£°æ§åˆ¶å‚æ•°
                "--noise_w", str(noise_w)              # æ·»åŠ éŸ³ç´ å®½åº¦å˜åŒ–æ§åˆ¶å‚æ•°
            ]
            
            process = await asyncio.create_subprocess_exec(
                *piper_command,
                stdin=subprocess.PIPE, stdout=subprocess.PIPE, stderr=subprocess.PIPE
            )
            
            _, stderr = await process.communicate(text.encode('utf-8'))
            
            if process.returncode == 0 and output_path.exists():
                with open(output_path, "rb") as f:
                    audio_bytes = f.read()
                
                print(f"Piper TTS è¯­éŸ³åˆæˆæˆåŠŸï¼Œè¿”å› {len(audio_bytes)} å­—èŠ‚æ•°æ®ã€‚")
                return audio_bytes
            else:
                raise Exception(f"Piperæ‰§è¡Œå¤±è´¥: {stderr.decode('utf-8', errors='ignore')}")

        except FileNotFoundError:
             print("é”™è¯¯ï¼šæ‰¾ä¸åˆ° 'piper' å‘½ä»¤ã€‚è¯·ç¡®ä¿æ‚¨å·²ç»é€šè¿‡ 'pip install piper-tts' å®‰è£…äº†å®ƒï¼Œå¹¶ä¸”å®ƒåœ¨ç³»ç»Ÿçš„PATHä¸­ã€‚")
             return None
        except Exception as e:
            print(f"âŒ Piper TTS åˆæˆå¤±è´¥: {e}")
            return None
        finally:
            # ç¡®ä¿ä¸´æ—¶æ–‡ä»¶è¢«åˆ é™¤
            if output_path.exists():
                output_path.unlink()
			


class AIService:
    """
    AIæœåŠ¡ç±»ï¼Œå°è£…äº†æ‰€æœ‰ä¸AIæ¨¡å‹ï¼ˆWhisper, DeepSeek, æœ¬åœ°TTSï¼‰çš„äº¤äº’ã€‚
    """
    def __init__(self):
        """
        åˆå§‹åŒ–AIæœåŠ¡ï¼ŒåŠ è½½Whisperæ¨¡å‹ã€é…ç½®DeepSeekå®¢æˆ·ç«¯å’Œæœ¬åœ°TTSå¼•æ“ã€‚
        """
        print("æ­£åœ¨åŠ è½½Whisperæ¨¡å‹...")
        self.whisper_model = whisper.load_model(config.WHISPER_MODEL)
        print("Whisperæ¨¡å‹åŠ è½½å®Œæ¯•ã€‚")

        print("æ­£åœ¨é…ç½®DeepSeekå®¢æˆ·ç«¯...")
        self.deepseek_client = OpenAI(api_key=config.DEEPSEEK_API_KEY, base_url=config.DEEPSEEK_BASE_URL)
        print("DeepSeekå®¢æˆ·ç«¯é…ç½®å®Œæ¯•ã€‚")

        print("æ­£åœ¨åˆå§‹åŒ–æœ¬åœ°TTSå¼•æ“...")
        self.local_tts_engine = LocalTTSEngine()
        print("æœ¬åœ°TTSå¼•æ“åˆå§‹åŒ–å®Œæ¯•ã€‚")

    async def text_to_wav(self, text: str, length_scale: float = 1.0, noise_scale: float = 0.667, noise_w: float = 0.8) -> str | None:
        """
        ä½¿ç”¨æœ¬åœ°TTSå¼•æ“å°†æ–‡æœ¬è½¬æ¢ä¸ºWAVæ ¼å¼çš„éŸ³é¢‘æ–‡ä»¶ã€‚
        """
        # ç›´æ¥è°ƒç”¨æœ¬åœ°TTSå¼•æ“çš„synthesizeæ–¹æ³•ï¼Œå¹¶ä¼ é€’è¯­é€Ÿå’Œå‘éŸ³é£æ ¼å‚æ•°
        return await self.local_tts_engine.synthesize(text, length_scale, noise_scale, noise_w)
		
    def transcribe_media_from_url(self, url: str) -> str:
        """
        ä»URLä¸‹è½½åª’ä½“æ–‡ä»¶ï¼ˆéŸ³é¢‘æˆ–è§†é¢‘ï¼‰ï¼Œè½¬å½•ä¸ºæ–‡å­—ï¼Œç„¶ååˆ é™¤ä¸´æ—¶æ–‡ä»¶ã€‚
        """
        temp_file_path = None
        try:
            print(f"æ­£åœ¨ä»URLä¸‹è½½åª’ä½“æ–‡ä»¶: {url}")
            response = requests.get(url, stream=True, headers=config.HEADERS, timeout=30)
            response.raise_for_status()

            path_part = url.split('?')[0]
            suffix = os.path.splitext(path_part)[1] or '.tmp'
            with tempfile.NamedTemporaryFile(delete=False, suffix=suffix) as temp_file:
                temp_file_path = temp_file.name
                for chunk in response.iter_content(chunk_size=8192):
                    temp_file.write(chunk)
            
            print(f"åª’ä½“æ–‡ä»¶å·²ä¸´æ—¶ä¿å­˜è‡³: {temp_file_path}")
            return self.transcribe_media_file(temp_file_path)

        except requests.RequestException as e:
            print(f"ä¸‹è½½åª’ä½“æ–‡ä»¶æ—¶å‘ç”Ÿé”™è¯¯: {e}")
            return ""
        except Exception as e:
            print(f"å¤„ç†åª’ä½“æ–‡ä»¶URLæ—¶å‘ç”ŸæœªçŸ¥é”™è¯¯: {e}")
            return ""
        finally:
            if temp_file_path and os.path.exists(temp_file_path):
                os.remove(temp_file_path)
                print(f"å·²æ¸…ç†ä¸´æ—¶æ–‡ä»¶: {temp_file_path}")

    def transcribe_media_file(self, file_path: str) -> str:
        """
        ä½¿ç”¨Whisperæ¨¡å‹å°†æŒ‡å®šçš„åª’ä½“æ–‡ä»¶ï¼ˆéŸ³é¢‘æˆ–è§†é¢‘ï¼‰è½¬æ¢ä¸ºæ–‡å­—ã€‚
        """
        print(f"æ­£åœ¨è¿›è¡Œè¯­éŸ³è¯†åˆ«: {file_path}")
        try:
            result = self.whisper_model.transcribe(file_path)
            text = result.get("text", "")
            print("è¯­éŸ³è¯†åˆ«å®Œæˆã€‚")
            return text
        except Exception as e:
            print(f"è¯­éŸ³è¯†åˆ«è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {e}")
            return ""

    def get_chat_completion(self, prompt: str) -> dict | None:
        """
        è°ƒç”¨DeepSeekèŠå¤©æ¨¡å‹è·å–ç­”æ¡ˆï¼Œå¹¶è§£æè¿”å›çš„JSONã€‚
        """
        print("æ­£åœ¨è¯·æ±‚DeepSeek AIè·å–ç­”æ¡ˆ (JSONæ¨¡å¼)...")
        try:
            messages = [
                ChatCompletionSystemMessageParam(role="system", content=prompts.SYSTEM_PROMPT),
                ChatCompletionUserMessageParam(role="user", content=prompt),
            ]
            
            ai_response = self.deepseek_client.chat.completions.create(
                model=config.DEEPSEEK_CHAT_MODEL,
                messages=messages,
                temperature=0.2,
                response_format={'type': 'json_object'}
            )
            
            answer_content = ai_response.choices[0].message.content
            print("å·²æ”¶åˆ°DeepSeekçš„å›å¤ã€‚")

            try:
                json_data = json.loads(answer_content)
                print("æˆåŠŸè§£æAIçš„ç­”æ¡ˆã€‚")
                return json_data
            except json.JSONDecodeError as e:
                print(f"é”™è¯¯ï¼šè§£æAIè¿”å›çš„JSONæ—¶å¤±è´¥: {e}")
                print(f"å°è¯•è§£æçš„å­—ç¬¦ä¸²: {answer_content}")
                return None

        except Exception as e:
            print(f"è°ƒç”¨DeepSeek APIæ—¶å‘ç”Ÿé”™è¯¯: {e}")
            return None
			

